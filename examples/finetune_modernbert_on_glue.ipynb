{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with ModernBERT & GLUE\n",
    "\n",
    "Created by: [Wayde Gilliam](https://twitter.com/waydegilliam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders Strike Back!\n",
    "\n",
    "Like many, I have fond memories of finetuning deberta, roberta and bert models for a number of Kaggle comps and real-world problems (e.g., NER, sentiment analysis, etc.).  Encoder models were \"the thing\" back in the day and continue to be the primary workhorse for many ML pipelines today though they have been eclipsed by recent advancements in LLMs which typically are based on decoder-only architectures. Long have we awaited a return to an encoder model for the modern world. With ModernBERT, that wait is over! ModernBERT is a new encoder-only model that incorporates the latest features in making neural networks more efficient, faster, and better at handling tasks that encoder models have long excelled at such at text classification.  In addition, ModernBERT allows us to break out of that max 512 token limit with their long context capabilities which give us 8,192 tokens to play with.\n",
    "\n",
    "In this tutorial, we'll go through the steps of fine-tuning ModernBERT for one of the GLUE tasks, MRPC.  We'll cover some key settings required to use it with the HuggingFace trainer and include with some recommended hyperparameters that have served us well in fine-tuning ModernBERT for GLUE.  We'll also see how to use the model for inference and cleanup the model from the GPU to free up resources.\n",
    "\n",
    "As an aside, I'm running all this code on a single 3090 with plenty of GPU memory to spare.\n",
    "\n",
    "Though not strictly necessary, **ModernBERT trains better with FlashAttention!**. Training and inference will be much faster with it installed. See below:\n",
    "\n",
    "ModernBERT is built on top of FlashAttention which is a highly optimized implementation of the attention mechanism that is faster and more memory efficient than the standard implementation.  ***The beauty of this is all you need to do is install it for ModernBERT to work with it!***  Here's how ...\n",
    "\n",
    "For NVIDIA GPUs with compute capability 8.0+ (Ampere/Ada/Hopper architecture - A100, A6000, RTX 3090, RTX 4090, H100 etc):\n",
    "```python\n",
    "pip install flash-attn --no-build-isolation\n",
    "```\n",
    "\n",
    "For older NVIDIA GPUs (pre-Ampere):\n",
    "```python\n",
    "pip install flash-attn --no-deps\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install transformers datasets accelerate scikit-learn -Uqq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from functools import partial\n",
    "import gc\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    TrainerCallback,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, f1_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "patents = load_dataset(\"MalavP/USPTO-3M\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 3198360, Subset size: 31984\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the dataset: 90% for \"dummy\" (discarded), 10% for the subset\n",
    "mini_patents = patents.train_test_split(\n",
    "    test_size=0.01,  # 10% of the original data\n",
    "    shuffle=True,   # Randomize selection\n",
    "    seed=42         # For reproducibility\n",
    ")[\"test\"]           # Keep the 10% test split\n",
    "mini_patents = mini_patents.rename_column(\"cpc_ids\", \"labels\")\n",
    "split_datasets = mini_patents.train_test_split(test_size=0.05, seed=42)\n",
    "train_dataset = split_datasets[\"train\"]\n",
    "eval_dataset = split_datasets[\"test\"]\n",
    "# Verify the size\n",
    "print(f\"Original size: {len(patents)}, Subset size: {len(mini_patents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/31984 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'labelx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m example\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Apply the function to your dataset (replace `your_dataset` with your dataset variable)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m mini_patents \u001b[38;5;241m=\u001b[39m mini_patents\u001b[38;5;241m.\u001b[39mmap(flatten_label)\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/datasets/arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/datasets/arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    565\u001b[0m }\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/datasets/arrow_dataset.py:3167\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3162\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3163\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3164\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3165\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3166\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3167\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3168\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3169\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/datasets/arrow_dataset.py:3528\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3526\u001b[0m _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3527\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[0;32m-> 3528\u001b[0m     example \u001b[38;5;241m=\u001b[39m apply_function_on_filtered_inputs(example, i, offset\u001b[38;5;241m=\u001b[39moffset)\n\u001b[1;32m   3529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m update_data:\n\u001b[1;32m   3530\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/datasets/arrow_dataset.py:3427\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3426\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3427\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m function(\u001b[38;5;241m*\u001b[39mfn_args, \u001b[38;5;241m*\u001b[39madditional_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_kwargs)\n\u001b[1;32m   3428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3429\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3430\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3431\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[64], line 3\u001b[0m, in \u001b[0;36mflatten_label\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten_label\u001b[39m(example):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# If the label is a list with one element, extract that element.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabelx\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m      4\u001b[0m         example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabelx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabelx\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m example\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/datasets/formatting/formatting.py:277\u001b[0m, in \u001b[0;36mLazyDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 277\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[key]\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys_to_format:\n\u001b[1;32m    279\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'labelx'"
     ]
    }
   ],
   "source": [
    "def flatten_label(example):\n",
    "    # If the label is a list with one element, extract that element.\n",
    "    if isinstance(example[\"labels\"], list):\n",
    "        example[\"labels\"] = example[\"labels\"][0]\n",
    "    return example\n",
    "\n",
    "# Apply the function to your dataset (replace `your_dataset` with your dataset variable)\n",
    "mini_patents = mini_patents.map(flatten_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 30384/30384 [00:10<00:00, 2966.63 examples/s]\n",
      "Map: 100%|██████████| 1600/1600 [00:00<00:00, 2976.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    " \n",
    "# Model id to load the tokenizer\n",
    "model_id = \"answerdotai/ModernBERT-base\"\n",
    "# model_id = \"google-bert/bert-base-uncased\"\n",
    "# Load Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# tokenizer.model_max_length = 512 # set model_max_length to 512 as prompts are not longer than 1024 tokens\n",
    " \n",
    "# Tokenize helper function\n",
    "def tokenize(batch):\n",
    "    # return tokenizer(batch['text'], padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "    return tokenizer(batch['text'], truncation=True)\n",
    "\n",
    "# Tokenize dataset\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "eval_dataset = eval_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. Load the model for sequence classification (adjust num_labels as needed).\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=len(set(mini_patents['labels'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7. Define a compute_metrics function to compute accuracy.\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    pred_labels = np.argmax(predictions, axis=-1)  # Convert logits to predicted class indices\n",
    "    acc = accuracy_score(labels, pred_labels)\n",
    "    return {\"accuracy\": acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your hyperparameters and task identifier\n",
    "train_bsz, val_bsz = 4, 4\n",
    "lr = 8e-5\n",
    "betas = (0.9, 0.98)\n",
    "n_epochs = 2\n",
    "eps = 1e-6\n",
    "wd = 8e-6\n",
    "task = \"your_task_name\"  # Set this to an appropriate identifier for your task\n",
    "# 8. Define training arguments using your specified hyperparameters.\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"aai_ModernBERT_{task}_ft\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=train_bsz,\n",
    "    per_device_eval_batch_size=val_bsz,\n",
    "    num_train_epochs=n_epochs,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    optim=\"adamw_torch\",\n",
    "    adam_beta1=betas[0],\n",
    "    adam_beta2=betas[1],\n",
    "    adam_epsilon=eps,\n",
    "    weight_decay=wd,\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    bf16=True,\n",
    "    bf16_full_eval=True,\n",
    "    push_to_hub=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/huggingface_hub-0.24.6-py3.8.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting accelerate\n",
      "  Using cached accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from accelerate) (2.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/huggingface_hub-0.24.6-py3.8.egg (from accelerate) (0.24.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from accelerate) (0.4.4)\n",
      "Requirement already satisfied: filelock in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.2)\n",
      "Requirement already satisfied: networkx in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hice1/groy8/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Using cached accelerate-1.3.0-py3-none-any.whl (336 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.3.0\n"
     ]
    }
   ],
   "source": [
    "! pip install -U accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 9. Create the Trainer with the compute_metrics function.\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=hf_data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"704d0327ee62d691da315b26b77a1ef42e972e6b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H04N,H04R\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[1][\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt\n",
    "Below is one common approach to handle your situation. In your dataset each example’s label is a string that contains two acceptable class codes (for example, `\"H04N,H04R\"`). Because the model’s classification head expects a single class per example (and Trainer expects a single integer in the `\"label\"` field), you need to do two things:\n",
    "\n",
    "1. **Preprocess the Data to Pick a Single Label (for Training)**\n",
    "2. **Optionally Adapt the Metric to Accept Either Label (for Evaluation)**\n",
    "\n",
    "Below are examples for both steps.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Preprocess Your Data to Select One Label\n",
    "\n",
    "You must decide on a rule for choosing one of the comma‐separated labels. For example, you might always choose the first label, or you could randomly pick one for each example (note that randomness during training is acceptable but might make evaluation noisy unless you fix the seed).\n",
    "\n",
    "You can write a preprocessing function like this:\n",
    "\n",
    "```python\n",
    "def preprocess_labels(example):\n",
    "    # Split the string into a list of possible labels.\n",
    "    possible_labels = example[\"label\"].split(\",\")\n",
    "    \n",
    "    # Option 1: Always choose the first label.\n",
    "    example[\"selected_label\"] = possible_labels[0]\n",
    "    \n",
    "    # Option 2: Randomly choose one of them.\n",
    "    # import random\n",
    "    # example[\"selected_label\"] = random.choice(possible_labels)\n",
    "    \n",
    "    # (Optionally) keep the full list in case you want to use it in evaluation.\n",
    "    example[\"raw_labels\"] = possible_labels\n",
    "    return example\n",
    "```\n",
    "\n",
    "Then map your dataset with this function:\n",
    "\n",
    "```python\n",
    "dataset = dataset.map(preprocess_labels)\n",
    "```\n",
    "\n",
    "Now your dataset has a new field `\"selected_label\"` that you will use for training. (The original `\"label\"` field can be dropped or kept for reference.)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Convert the Selected Label to an Integer\n",
    "\n",
    "The Trainer and `AutoModelForSequenceClassification` expect the label to be an integer. So you need to build a mapping from label strings to integer IDs. For example:\n",
    "\n",
    "```python\n",
    "# Collect all possible labels from the raw labels.\n",
    "all_labels = set()\n",
    "for example in dataset:\n",
    "    # Here, raw_labels is a list such as ['H04N', 'H04R']\n",
    "    all_labels.update(example[\"raw_labels\"])\n",
    "all_labels = sorted(all_labels)\n",
    "\n",
    "label2id = {label: idx for idx, label in enumerate(all_labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "def convert_label_to_int(example):\n",
    "    # Use the selected label for training.\n",
    "    example[\"label\"] = label2id[example[\"selected_label\"]]\n",
    "    return example\n",
    "\n",
    "# Convert the selected label into an integer.\n",
    "dataset = dataset.map(convert_label_to_int)\n",
    "```\n",
    "\n",
    "When you load your model you can pass the label mappings:\n",
    "\n",
    "```python\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"your-checkpoint\",\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "```\n",
    "\n",
    "At this point your training examples have a single integer label in the `\"label\"` field. You can now tokenize your texts as before and train the model in the usual way.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Adapting the Metric (Optional)\n",
    "\n",
    "If you would like your evaluation metric to treat a prediction as correct when it matches **either** acceptable label (rather than only the one used for training), you’ll need to preserve the original list of acceptable labels (which we stored in `\"raw_labels\"`). Then you must customize your metric function.\n",
    "\n",
    "**Important:**  \n",
    "By default, the Trainer’s evaluation loop passes only the logits and the (processed) integer labels. To use `\"raw_labels\"` in your metric computation you have two main options:\n",
    "\n",
    "- **A. Use a Custom Data Collator:**  \n",
    "  Modify your data collator so that it does not remove extra fields (like `\"raw_labels\"`) when batching. Then your `compute_metrics` function will receive extra information from the evaluation batch.\n",
    "\n",
    "- **B. Post‑Process Evaluation:**  \n",
    "  Run the evaluation on the raw (unbatched) dataset after predictions have been made. In this function, you would:\n",
    "  \n",
    "  1. Get the model’s predictions (as integer IDs).\n",
    "  2. Convert them to label strings using `id2label`.\n",
    "  3. For each example, compare the predicted label to the list stored in `\"raw_labels\"`, and mark it as correct if it is contained there.\n",
    "\n",
    "For example, here is a sketch of how you might write a custom metric function if you can arrange to have access to the original `\"raw_labels\"` (assume that you have modified your data collator or evaluation loop accordingly):\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics_with_raw_labels(eval_pred):\n",
    "    logits, labels, batch = eval_pred  # This assumes your eval loop provides extra batch info.\n",
    "    pred_ids = np.argmax(logits, axis=-1)\n",
    "    predictions = [id2label[p] for p in pred_ids]\n",
    "    \n",
    "    correct = 0\n",
    "    # Assuming batch[\"raw_labels\"] is a list of lists (e.g., [['H04N','H04R'], ...])\n",
    "    for pred, raw in zip(predictions, batch[\"raw_labels\"]):\n",
    "        if pred in raw:\n",
    "            correct += 1\n",
    "    accuracy = correct / len(predictions)\n",
    "    \n",
    "    return {\"accuracy\": accuracy}\n",
    "```\n",
    "\n",
    "**Note:**  \n",
    "If adapting the evaluation loop to include `\"raw_labels\"` is too much extra work, you can simply train (and evaluate) on the single selected label. In that case your metric function can remain the standard one (e.g. using accuracy or F1) that compares the model’s prediction with the integer label in `\"label\"`.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "- **For training:**  \n",
    "  Preprocess each example by splitting the comma‑separated string, choose one label (e.g. the first), and convert it to an integer using a mapping.\n",
    "  \n",
    "- **For evaluation:**  \n",
    "  – *Simple approach:* Use the same single label for computing accuracy.  \n",
    "  – *Advanced approach:* Keep the list of acceptable labels and customize your evaluation to count a prediction as correct if it appears in that list.\n",
    "\n",
    "Choose the approach that best fits your needs. If both labels are acceptable for your downstream task, training on a single (fixed or randomly chosen) label is often sufficient; if you really need to consider the ambiguity during evaluation, then you’ll need to adapt your metric (or evaluation loop) accordingly.\n",
    "\n",
    "Happy fine‑tuning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type dict that is 294992 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type dict that is 207616 bytes\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`labels` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:777\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 777\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m as_tensor(value)\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:739\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors.<locals>.as_tensor\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(value))\n\u001b[0;32m--> 739\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(value)\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/transformers/trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   2172\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   2173\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   2174\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   2175\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2176\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/transformers/trainer.py:2480\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2478\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2479\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2480\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_batch_samples(epoch_iterator, num_batches)\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[1;32m   2482\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/transformers/trainer.py:5153\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches)\u001b[0m\n\u001b[1;32m   5151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m   5152\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5153\u001b[0m         batch_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mnext\u001b[39m(epoch_iterator)]\n\u001b[1;32m   5154\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   5155\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/accelerate/data_loader.py:563\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 563\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/transformers/data/data_collator.py:271\u001b[0m, in \u001b[0;36mDataCollatorWithPadding.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m--> 271\u001b[0m     batch \u001b[38;5;241m=\u001b[39m pad_without_fast_tokenizer_warning(\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer,\n\u001b[1;32m    273\u001b[0m         features,\n\u001b[1;32m    274\u001b[0m         padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding,\n\u001b[1;32m    275\u001b[0m         max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m    276\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_to_multiple_of,\n\u001b[1;32m    277\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_tensors,\n\u001b[1;32m    278\u001b[0m     )\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m    280\u001b[0m         batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/transformers/data/data_collator.py:66\u001b[0m, in \u001b[0;36mpad_without_fast_tokenizer_warning\u001b[0;34m(tokenizer, *pad_args, **pad_kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mdeprecation_warnings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking-to-pad-a-fast-tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     padded \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;241m*\u001b[39mpad_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpad_kwargs)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# Restore the state of the warning.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     tokenizer\u001b[38;5;241m.\u001b[39mdeprecation_warnings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking-to-pad-a-fast-tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m warning_state\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3388\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, padding_side, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   3385\u001b[0m             batch_outputs[key] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   3386\u001b[0m         batch_outputs[key]\u001b[38;5;241m.\u001b[39mappend(value)\n\u001b[0;32m-> 3388\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BatchEncoding(batch_outputs, tensor_type\u001b[38;5;241m=\u001b[39mreturn_tensors)\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:241\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    237\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_to_tensors(tensor_type\u001b[38;5;241m=\u001b[39mtensor_type, prepend_batch_axis\u001b[38;5;241m=\u001b[39mprepend_batch_axis)\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/bert24-h200/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:793\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    789\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    790\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    791\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    792\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    794\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    795\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncation=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m features (`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    797\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    798\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`labels` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is GLUE?\n",
    "\n",
    "The [General Language Understanding Evaluation (GLUE) benchmark](https://gluebenchmark.com/) is a collection of nine diverse natural language understanding tasks designed to evaluate and compare the performance of NLP models across various language comprehension challenges. By providing a standardized framework, GLUE facilitates the development of models that generalize well across multiple tasks, promoting advancements in creating robust and versatile language understanding systems. \n",
    "\n",
    "Let's put this all these tasks in a dictionary along with some other helpful metadata about each one that might prove useful to iteratting over all of them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3117e_row0_col0, #T_3117e_row0_col1, #T_3117e_row0_col2, #T_3117e_row0_col3, #T_3117e_row0_col4, #T_3117e_row0_col5, #T_3117e_row1_col0, #T_3117e_row1_col1, #T_3117e_row1_col2, #T_3117e_row1_col3, #T_3117e_row1_col4, #T_3117e_row1_col5, #T_3117e_row2_col0, #T_3117e_row2_col1, #T_3117e_row2_col2, #T_3117e_row2_col3, #T_3117e_row2_col4, #T_3117e_row2_col5, #T_3117e_row3_col0, #T_3117e_row3_col1, #T_3117e_row3_col2, #T_3117e_row3_col3, #T_3117e_row3_col4, #T_3117e_row3_col5, #T_3117e_row4_col0, #T_3117e_row4_col1, #T_3117e_row4_col2, #T_3117e_row4_col3, #T_3117e_row4_col4, #T_3117e_row4_col5, #T_3117e_row5_col0, #T_3117e_row5_col1, #T_3117e_row5_col2, #T_3117e_row5_col3, #T_3117e_row5_col4, #T_3117e_row5_col5, #T_3117e_row6_col0, #T_3117e_row6_col1, #T_3117e_row6_col2, #T_3117e_row6_col3, #T_3117e_row6_col4, #T_3117e_row6_col5, #T_3117e_row7_col0, #T_3117e_row7_col1, #T_3117e_row7_col2, #T_3117e_row7_col3, #T_3117e_row7_col4, #T_3117e_row7_col5, #T_3117e_row8_col0, #T_3117e_row8_col1, #T_3117e_row8_col2, #T_3117e_row8_col3, #T_3117e_row8_col4, #T_3117e_row8_col5, #T_3117e_row9_col0, #T_3117e_row9_col1, #T_3117e_row9_col2, #T_3117e_row9_col3, #T_3117e_row9_col4, #T_3117e_row9_col5 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3117e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3117e_level0_col0\" class=\"col_heading level0 col0\" >Abbr</th>\n",
       "      <th id=\"T_3117e_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_3117e_level0_col2\" class=\"col_heading level0 col2\" >Task type</th>\n",
       "      <th id=\"T_3117e_level0_col3\" class=\"col_heading level0 col3\" >Description</th>\n",
       "      <th id=\"T_3117e_level0_col4\" class=\"col_heading level0 col4\" >Size</th>\n",
       "      <th id=\"T_3117e_level0_col5\" class=\"col_heading level0 col5\" >Metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3117e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3117e_row0_col0\" class=\"data row0 col0\" >CoLA</td>\n",
       "      <td id=\"T_3117e_row0_col1\" class=\"data row0 col1\" >Corpus of Linguistic Acceptability</td>\n",
       "      <td id=\"T_3117e_row0_col2\" class=\"data row0 col2\" >Single-Sentence Task</td>\n",
       "      <td id=\"T_3117e_row0_col3\" class=\"data row0 col3\" >Predict whether a sequence is a grammatical English sentence</td>\n",
       "      <td id=\"T_3117e_row0_col4\" class=\"data row0 col4\" >8.5k</td>\n",
       "      <td id=\"T_3117e_row0_col5\" class=\"data row0 col5\" >Matthews corr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3117e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3117e_row1_col0\" class=\"data row1 col0\" >SST-2</td>\n",
       "      <td id=\"T_3117e_row1_col1\" class=\"data row1 col1\" >Stanford Sentiment Treebank</td>\n",
       "      <td id=\"T_3117e_row1_col2\" class=\"data row1 col2\" >Single-Sentence Task</td>\n",
       "      <td id=\"T_3117e_row1_col3\" class=\"data row1 col3\" >Predict the sentiment of a given sentence</td>\n",
       "      <td id=\"T_3117e_row1_col4\" class=\"data row1 col4\" >67k</td>\n",
       "      <td id=\"T_3117e_row1_col5\" class=\"data row1 col5\" >Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3117e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3117e_row2_col0\" class=\"data row2 col0\" >MRPC</td>\n",
       "      <td id=\"T_3117e_row2_col1\" class=\"data row2 col1\" >Microsoft Research Paraphrase Corpus</td>\n",
       "      <td id=\"T_3117e_row2_col2\" class=\"data row2 col2\" >Similarity and Paraphrase Tasks</td>\n",
       "      <td id=\"T_3117e_row2_col3\" class=\"data row2 col3\" >Predict whether two sentences are semantically equivalent</td>\n",
       "      <td id=\"T_3117e_row2_col4\" class=\"data row2 col4\" >3.7k</td>\n",
       "      <td id=\"T_3117e_row2_col5\" class=\"data row2 col5\" >F1/Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3117e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3117e_row3_col0\" class=\"data row3 col0\" >SST-B</td>\n",
       "      <td id=\"T_3117e_row3_col1\" class=\"data row3 col1\" >Semantic Textual Similarity Benchmark</td>\n",
       "      <td id=\"T_3117e_row3_col2\" class=\"data row3 col2\" >Similarity and Paraphrase Tasks</td>\n",
       "      <td id=\"T_3117e_row3_col3\" class=\"data row3 col3\" >Predict the similarity score for two sentences on a scale from 1 to 5</td>\n",
       "      <td id=\"T_3117e_row3_col4\" class=\"data row3 col4\" >7k</td>\n",
       "      <td id=\"T_3117e_row3_col5\" class=\"data row3 col5\" >Pearson/Spearman corr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3117e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3117e_row4_col0\" class=\"data row4 col0\" >QQP</td>\n",
       "      <td id=\"T_3117e_row4_col1\" class=\"data row4 col1\" >Quora question pair</td>\n",
       "      <td id=\"T_3117e_row4_col2\" class=\"data row4 col2\" >Similarity and Paraphrase Tasks</td>\n",
       "      <td id=\"T_3117e_row4_col3\" class=\"data row4 col3\" >Predict if two questions are a paraphrase of one another</td>\n",
       "      <td id=\"T_3117e_row4_col4\" class=\"data row4 col4\" >364k</td>\n",
       "      <td id=\"T_3117e_row4_col5\" class=\"data row4 col5\" >F1/Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3117e_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_3117e_row5_col0\" class=\"data row5 col0\" >MNLI</td>\n",
       "      <td id=\"T_3117e_row5_col1\" class=\"data row5 col1\" >Mulit-Genre Natural Language Inference</td>\n",
       "      <td id=\"T_3117e_row5_col2\" class=\"data row5 col2\" >Inference Tasks</td>\n",
       "      <td id=\"T_3117e_row5_col3\" class=\"data row5 col3\" >Predict whether the premise entails, contradicts or is neutral to the hypothesis</td>\n",
       "      <td id=\"T_3117e_row5_col4\" class=\"data row5 col4\" >393k</td>\n",
       "      <td id=\"T_3117e_row5_col5\" class=\"data row5 col5\" >Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3117e_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_3117e_row6_col0\" class=\"data row6 col0\" >MNLI</td>\n",
       "      <td id=\"T_3117e_row6_col1\" class=\"data row6 col1\" >Mulit-Genre Natural Language Inference</td>\n",
       "      <td id=\"T_3117e_row6_col2\" class=\"data row6 col2\" >Inference Tasks</td>\n",
       "      <td id=\"T_3117e_row6_col3\" class=\"data row6 col3\" >Predict whether the premise entails, contradicts or is neutral to the hypothesis</td>\n",
       "      <td id=\"T_3117e_row6_col4\" class=\"data row6 col4\" >393k</td>\n",
       "      <td id=\"T_3117e_row6_col5\" class=\"data row6 col5\" >Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3117e_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_3117e_row7_col0\" class=\"data row7 col0\" >QNLI</td>\n",
       "      <td id=\"T_3117e_row7_col1\" class=\"data row7 col1\" >Stanford Question Answering Dataset</td>\n",
       "      <td id=\"T_3117e_row7_col2\" class=\"data row7 col2\" >Inference Tasks</td>\n",
       "      <td id=\"T_3117e_row7_col3\" class=\"data row7 col3\" >Predict whether the context sentence contains the answer to the question</td>\n",
       "      <td id=\"T_3117e_row7_col4\" class=\"data row7 col4\" >105k</td>\n",
       "      <td id=\"T_3117e_row7_col5\" class=\"data row7 col5\" >Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3117e_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_3117e_row8_col0\" class=\"data row8 col0\" >RTE</td>\n",
       "      <td id=\"T_3117e_row8_col1\" class=\"data row8 col1\" >Recognize Textual Entailment</td>\n",
       "      <td id=\"T_3117e_row8_col2\" class=\"data row8 col2\" >Inference Tasks</td>\n",
       "      <td id=\"T_3117e_row8_col3\" class=\"data row8 col3\" >Predict whether one sentece entails another</td>\n",
       "      <td id=\"T_3117e_row8_col4\" class=\"data row8 col4\" >2.5k</td>\n",
       "      <td id=\"T_3117e_row8_col5\" class=\"data row8 col5\" >Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3117e_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_3117e_row9_col0\" class=\"data row9 col0\" >WNLI</td>\n",
       "      <td id=\"T_3117e_row9_col1\" class=\"data row9 col1\" >Winograd Schema Challenge</td>\n",
       "      <td id=\"T_3117e_row9_col2\" class=\"data row9 col2\" >Inference Tasks</td>\n",
       "      <td id=\"T_3117e_row9_col3\" class=\"data row9 col3\" >Predict if the sentence with the pronoun substituted is entailed by the original sentence</td>\n",
       "      <td id=\"T_3117e_row9_col4\" class=\"data row9 col4\" >634</td>\n",
       "      <td id=\"T_3117e_row9_col5\" class=\"data row9 col5\" >Accuracy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffef3f20310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glue_tasks = {\n",
    "    \"cola\": {\n",
    "        \"abbr\": \"CoLA\",\n",
    "        \"name\": \"Corpus of Linguistic Acceptability\",\n",
    "        \"description\": \"Predict whether a sequence is a grammatical English sentence\",\n",
    "        \"task_type\": \"Single-Sentence Task\",\n",
    "        \"domain\": \"Misc.\",\n",
    "        \"size\": \"8.5k\",\n",
    "        \"metrics\": \"Matthews corr.\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"sentence\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [matthews_corrcoef],\n",
    "        \"n_labels\": 2,\n",
    "    },\n",
    "    \"sst2\": {\n",
    "        \"abbr\": \"SST-2\",\n",
    "        \"name\": \"Stanford Sentiment Treebank\",\n",
    "        \"description\": \"Predict the sentiment of a given sentence\",\n",
    "        \"task_type\": \"Single-Sentence Task\",\n",
    "        \"domain\": \"Movie reviews\",\n",
    "        \"size\": \"67k\",\n",
    "        \"metrics\": \"Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"sentence\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [accuracy_score],\n",
    "        \"n_labels\": 2,\n",
    "    },\n",
    "    \"mrpc\": {\n",
    "        \"abbr\": \"MRPC\",\n",
    "        \"name\": \"Microsoft Research Paraphrase Corpus\",\n",
    "        \"description\": \"Predict whether two sentences are semantically equivalent\",\n",
    "        \"task_type\": \"Similarity and Paraphrase Tasks\",\n",
    "        \"domain\": \"News\",\n",
    "        \"size\": \"3.7k\",\n",
    "        \"metrics\": \"F1/Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"sentence1\", \"sentence2\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [accuracy_score, f1_score],\n",
    "        \"n_labels\": 2,\n",
    "    },\n",
    "    \"stsb\": {\n",
    "        \"abbr\": \"SST-B\",\n",
    "        \"name\": \"Semantic Textual Similarity Benchmark\",\n",
    "        \"description\": \"Predict the similarity score for two sentences on a scale from 1 to 5\",\n",
    "        \"task_type\": \"Similarity and Paraphrase Tasks\",\n",
    "        \"domain\": \"Misc.\",\n",
    "        \"size\": \"7k\",\n",
    "        \"metrics\": \"Pearson/Spearman corr.\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"sentence1\", \"sentence2\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [pearsonr, spearmanr],\n",
    "        \"n_labels\": 1,\n",
    "    },\n",
    "    \"qqp\": {\n",
    "        \"abbr\": \"QQP\",\n",
    "        \"name\": \"Quora question pair\",\n",
    "        \"description\": \"Predict if two questions are a paraphrase of one another\",\n",
    "        \"task_type\": \"Similarity and Paraphrase Tasks\",\n",
    "        \"domain\": \"Social QA questions\",\n",
    "        \"size\": \"364k\",\n",
    "        \"metrics\": \"F1/Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"question1\", \"question2\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [f1_score, accuracy_score],\n",
    "        \"n_labels\": 2,\n",
    "    },\n",
    "    \"mnli-matched\": {\n",
    "        \"abbr\": \"MNLI\",\n",
    "        \"name\": \"Mulit-Genre Natural Language Inference\",\n",
    "        \"description\": \"Predict whether the premise entails, contradicts or is neutral to the hypothesis\",\n",
    "        \"task_type\": \"Inference Tasks\",\n",
    "        \"domain\": \"Misc.\",\n",
    "        \"size\": \"393k\",\n",
    "        \"metrics\": \"Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation_matched\", \"test\": \"test_matched\"},\n",
    "        \"inputs\": [\"premise\", \"hypothesis\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [accuracy_score],\n",
    "        \"n_labels\": 3,\n",
    "    },\n",
    "    \"mnli-mismatched\": {\n",
    "        \"abbr\": \"MNLI\",\n",
    "        \"name\": \"Mulit-Genre Natural Language Inference\",\n",
    "        \"description\": \"Predict whether the premise entails, contradicts or is neutral to the hypothesis\",\n",
    "        \"task_type\": \"Inference Tasks\",\n",
    "        \"domain\": \"Misc.\",\n",
    "        \"size\": \"393k\",\n",
    "        \"metrics\": \"Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation_mismatched\", \"test\": \"test_mismatched\"},\n",
    "        \"inputs\": [\"premise\", \"hypothesis\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [accuracy_score],\n",
    "        \"n_labels\": 3,\n",
    "    },\n",
    "    \"qnli\": {\n",
    "        \"abbr\": \"QNLI\",\n",
    "        \"name\": \"Stanford Question Answering Dataset\",\n",
    "        \"description\": \"Predict whether the context sentence contains the answer to the question\",\n",
    "        \"task_type\": \"Inference Tasks\",\n",
    "        \"domain\": \"Wikipedia\",\n",
    "        \"size\": \"105k\",\n",
    "        \"metrics\": \"Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"question\", \"sentence\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [accuracy_score],\n",
    "        \"n_labels\": 2,\n",
    "    },\n",
    "    \"rte\": {\n",
    "        \"abbr\": \"RTE\",\n",
    "        \"name\": \"Recognize Textual Entailment\",\n",
    "        \"description\": \"Predict whether one sentece entails another\",\n",
    "        \"task_type\": \"Inference Tasks\",\n",
    "        \"domain\": \"News, Wikipedia\",\n",
    "        \"size\": \"2.5k\",\n",
    "        \"metrics\": \"Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"sentence1\", \"sentence2\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [accuracy_score],\n",
    "        \"n_labels\": 2,\n",
    "    },\n",
    "    \"wnli\": {\n",
    "        \"abbr\": \"WNLI\",\n",
    "        \"name\": \"Winograd Schema Challenge\",\n",
    "        \"description\": \"Predict if the sentence with the pronoun substituted is entailed by the original sentence\",\n",
    "        \"task_type\": \"Inference Tasks\",\n",
    "        \"domain\": \"Fiction books\",\n",
    "        \"size\": \"634\",\n",
    "        \"metrics\": \"Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"sentence1\", \"sentence2\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [accuracy_score],\n",
    "        \"n_labels\": 2,\n",
    "    },\n",
    "}\n",
    "\n",
    "# for v in glue_tasks.values(): print(v)\n",
    "glue_tasks.values()\n",
    "\n",
    "glue_df = pd.DataFrame(glue_tasks.values(), columns=[\"abbr\", \"name\", \"task_type\", \"description\", \"size\", \"metrics\"])\n",
    "glue_df.columns = glue_df.columns.str.replace(\"_\", \" \").str.capitalize()\n",
    "display(glue_df.style.set_properties(**{\"text-align\": \"left\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb  4 22:19:56 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          On  |   00000000:25:00.0 Off |                    0 |\n",
      "| N/A   33C    P0             43W /  300W |       4MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Fine-Tune ModernBERT for MRPC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "ModernBERT currently comes in two flavors, base and large. To keep things lean and mean, we'll use the \"answerdotai/ModernBERT-base\" checkpoint for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"mrpc\"\n",
    "task_meta = glue_tasks[task]\n",
    "train_ds_name = task_meta[\"dataset_names\"][\"train\"]\n",
    "valid_ds_name = task_meta[\"dataset_names\"][\"valid\"]\n",
    "test_ds_name = task_meta[\"dataset_names\"][\"test\"]\n",
    "\n",
    "task_inputs = task_meta[\"inputs\"]\n",
    "task_target = task_meta[\"target\"]\n",
    "n_labels = task_meta[\"n_labels\"]\n",
    "task_metrics = task_meta[\"metric_funcs\"]\n",
    "\n",
    "checkpoint = \"answerdotai/ModernBERT-base\"  # \"answerdotai/ModernBERT-base\", \"answerdotai/ModernBERT-large\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the `Datasets` library to load the data.  As its always recommended to \"look at your data\" before we get training, we'll also print out a single example to see what we're working with as well as the features of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 3668\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 1725\n",
      "    })\n",
      "})\n",
      "\n",
      "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .', 'label': 1, 'idx': 0}\n",
      "\n",
      "{'sentence1': Value(dtype='string', id=None), 'sentence2': Value(dtype='string', id=None), 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None), 'idx': Value(dtype='int32', id=None)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"glue\", task)\n",
    "\n",
    "print(f\"{raw_datasets}\\n\")\n",
    "print(f\"{raw_datasets[train_ds_name][0]}\\n\")\n",
    "print(f\"{raw_datasets[train_ds_name].features}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the following dictionaries when building our model with `AutoModelForSequenceClassification` to map between the label ids and names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_maps(raw_datasets, train_ds_name):\n",
    "    labels = raw_datasets[train_ds_name].features[\"label\"]\n",
    "\n",
    "    id2label = {idx: name.upper() for idx, name in enumerate(labels.names)} if hasattr(labels, \"names\") else None\n",
    "    label2id = {name.upper(): idx for idx, name in enumerate(labels.names)} if hasattr(labels, \"names\") else None\n",
    "\n",
    "    return id2label, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'NOT_EQUIVALENT', 1: 'EQUIVALENT'}\n",
      "{'NOT_EQUIVALENT': 0, 'EQUIVALENT': 1}\n"
     ]
    }
   ],
   "source": [
    "id2label, label2id = get_label_maps(raw_datasets, train_ds_name)\n",
    "\n",
    "print(f\"{id2label}\")\n",
    "print(f\"{label2id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MRPC is a sentence-pair classification task where we're given two sentences and asked to predict whether they are paraphrases of one another.  The dataset is split into train, validation and test sets. We'll need to keep all this in mind when we set up tokenization next with `AutoTokenizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "\n",
    "Next we define our Tokenizer and a preprocess function to create the input_ids, attention_mask, and token_type_ids the model nees to train.  For this example, including `truncation=True` is enough as we'll rely on our data collation function below to put our batches into the correct shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence1', 'sentence2']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, task_inputs):\n",
    "    inps = [examples[inp] for inp in task_inputs]\n",
    "    tokenized = hf_tokenizer(*inps, truncation=True)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 408/408 [00:00<00:00, 3383.27 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 3668\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1725\n",
      "    })\n",
      "})\n",
      "\n",
      "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .', 'label': 1, 'idx': 0, 'input_ids': [50281, 8096, 287, 9877, 10145, 521, 4929, 1157, 5207, 344, 1925, 346, 253, 5517, 346, 1157, 273, 21547, 940, 12655, 521, 1941, 964, 50282, 7676, 24247, 281, 779, 347, 760, 346, 253, 5517, 346, 1157, 3052, 287, 9877, 10145, 521, 4929, 273, 21547, 940, 12655, 521, 1941, 964, 50282], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "\n",
      "{'sentence1': Value(dtype='string', id=None), 'sentence2': Value(dtype='string', id=None), 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None), 'idx': Value(dtype='int32', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(partial(preprocess_function, task_inputs=task_inputs), batched=True)\n",
    "\n",
    "print(f\"{tokenized_datasets}\\n\")\n",
    "print(f\"{tokenized_datasets[train_ds_name][0]}\\n\")\n",
    "print(f\"{tokenized_datasets[train_ds_name].features}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always good to see what the tokenizer is doing to our data to ensure the special tokens are where we expect them to be!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]Amrozi accused his brother, whom he called \" the witness \", of deliberately distorting his evidence.[SEP]Referring to him as only \" the witness \", Amrozi accused his brother of deliberately distorting his evidence.[SEP]'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_tokenizer.decode(tokenized_datasets[train_ds_name][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use our `task_metrics` to compute the metrics for our model.  We'll return a dictionary of the metric name and value for each metric we're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred, task_metrics):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    metrics_d = {}\n",
    "    for metric_func in task_metrics:\n",
    "        metric_name = metric_func.__name__\n",
    "        if metric_name in [\"pearsonr\", \"spearmanr\"]:\n",
    "            score = metric_func(labels, np.squeeze(predictions))\n",
    "        else:\n",
    "            score = metric_func(np.argmax(predictions, axis=-1), labels)\n",
    "\n",
    "        if isinstance(score, tuple):\n",
    "            metrics_d[metric_func.__name__] = score[0]\n",
    "        else:\n",
    "            metrics_d[metric_func.__name__] = score\n",
    "\n",
    "    return metrics_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "This is where the fun begins! Here we setup a few hyperparameters than have proven to work well for us in fine-tuning ModernBERT-base on GLUE tasks.  We'll also setup our model, data collator, and training arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bsz, val_bsz = 32, 32\n",
    "lr = 8e-5\n",
    "betas = (0.9, 0.98)\n",
    "n_epochs = 2\n",
    "eps = 1e-6\n",
    "wd = 8e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When configuring `AutoModelForSequenceClassification`, two settings are critical to get things working with the HuggingFace `Trainer`. One is the `num_labels` we're expecting and the other is to set `compile=False` to avoid using the `torch.compile` function which is not supported in Transformers at the time of this writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "hf_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, num_labels=n_labels, id2label=id2label, label2id=label2id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collation is easy for GLUE tasks as we can use the `DataCollatorWithPadding` class to pad our input_ids and attention_mask to the max length in the batch.\n",
    "\n",
    "**Note**: If you have installed Flash Attention, ModernBERT removes the padding internally, which makes it the fastest version. SPDA and Eager mode will be slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_data_collator = DataCollatorWithPadding(tokenizer=hf_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the pieces in place, we can now setup our `TrainingArguments` and `Trainer` and get to training! Lots of customization is possible here and it is recommended to play with different schedulers and the hyperparameters we've started y'all off with above to improve results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"aai_ModernBERT_{task}_ft\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=train_bsz,\n",
    "    per_device_eval_batch_size=val_bsz,\n",
    "    num_train_epochs=n_epochs,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    optim=\"adamw_torch\",\n",
    "    adam_beta1=betas[0],\n",
    "    adam_beta2=betas[1],\n",
    "    adam_epsilon=eps,\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    bf16=True,\n",
    "    bf16_full_eval=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /storage/ice1/0/1/groy8/conda/envs/bert24/lib/python3.11/site-packages/huggingface_hub-0.24.6-py3.8.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define `TrainerCallback` so that we can capture all the training and evaluation logs and store them for later analysis. By default, the `Trainer` class will only keep the latest logs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.training_history = {\"train\": [], \"eval\": []}\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            if \"loss\" in logs:  # Training logs\n",
    "                self.training_history[\"train\"].append(logs)\n",
    "            elif \"eval_loss\" in logs:  # Evaluation logs\n",
    "                self.training_history[\"eval\"].append(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=hf_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[train_ds_name],\n",
    "    eval_dataset=tokenized_datasets[valid_ds_name],\n",
    "    processing_class=hf_tokenizer,\n",
    "    data_collator=hf_data_collator,\n",
    "    compute_metrics=partial(compute_metrics, task_metrics=task_metrics),\n",
    ")\n",
    "\n",
    "metrics_callback = MetricsCallback()\n",
    "trainer.add_callback(metrics_callback)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "train_history_df = pd.DataFrame(metrics_callback.training_history[\"train\"])\n",
    "train_history_df = train_history_df.add_prefix(\"train_\")\n",
    "eval_history_df = pd.DataFrame(metrics_callback.training_history[\"eval\"])\n",
    "train_res_df = pd.concat([train_history_df, eval_history_df], axis=1)\n",
    "\n",
    "args_df = pd.DataFrame([training_args.to_dict()])\n",
    "\n",
    "display(train_res_df)\n",
    "display(args_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "There'a number of options for inference within the HuggingFace ecosystem.  We'll go a bit old school here and just use the `forward` method of the model. We're not uploading this model to the hub, but this is an easy enough task for you to try out on your own should you like to share your ModernBERT finetune :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2422, -1.5234]], device='cuda:0')\n",
      "Prediction: NOT_EQUIVALENT\n"
     ]
    }
   ],
   "source": [
    "ex_1 = \"The quick brown fox jumps over the lazy dog.\"\n",
    "ex_2 = \"I love lamp!\"\n",
    "\n",
    "inf_inputs = hf_tokenizer(ex_1, ex_2, return_tensors=\"pt\")\n",
    "inf_inputs = inf_inputs.to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = hf_model(**inf_inputs).logits\n",
    "\n",
    "print(logits)\n",
    "print(f\"Prediction: {hf_model.config.id2label[logits.argmax().item()]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(things_to_delete: list | None = None):\n",
    "    if things_to_delete is not None:\n",
    "        for thing in things_to_delete:\n",
    "            if thing is not None:\n",
    "                del thing\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup(things_to_delete=[hf_model, trainer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train all the GLUE!\n",
    "\n",
    "If you got this far you're probably wondering why I put together that dictionary of GLUE tasks if all we're doing is finetuning a single model. The answer is basically that I'm a good and lazy programmer who would like to easily run hyperparameter sweeps and/or fine-tunes on all the GLUE tasks. So ... let's do that!\n",
    "\n",
    "We'll run with the training hyperparameters specified above and I leave it to the reader to improve the method below to be able to override these values should folks be looking for something to do :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_glue_task(\n",
    "    task: str, checkpoint: str = \"answerdotai/ModernBERT-base\", train_subset: int | None = None, do_cleanup: bool = True\n",
    "):  # 1. Load the task metadata\n",
    "    task_meta = glue_tasks[task]\n",
    "    train_ds_name = task_meta[\"dataset_names\"][\"train\"]\n",
    "    valid_ds_name = task_meta[\"dataset_names\"][\"valid\"]\n",
    "\n",
    "    task_inputs = task_meta[\"inputs\"]\n",
    "    n_labels = task_meta[\"n_labels\"]\n",
    "    task_metrics = task_meta[\"metric_funcs\"]\n",
    "\n",
    "    # 2. Load the dataset\n",
    "    raw_datasets = load_dataset(\"glue\", task.split(\"-\")[0] if \"-\" in task else task)\n",
    "    if train_subset is not None and len(raw_datasets[\"train\"]) > train_subset:\n",
    "        raw_datasets[\"train\"] = raw_datasets[\"train\"].shuffle(seed=42).select(range(train_subset))\n",
    "\n",
    "    id2label, label2id = get_label_maps(raw_datasets, train_ds_name)\n",
    "\n",
    "    # 3. Load the tokenizer\n",
    "    hf_tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "    tokenized_datasets = raw_datasets.map(partial(preprocess_function, task_inputs=task_inputs), batched=True)\n",
    "\n",
    "    # 4. Define the compute metrics function\n",
    "    task_compute_metrics = partial(compute_metrics, task_metrics=task_metrics)\n",
    "\n",
    "    # 5. Load the model and data collator\n",
    "    model_additional_kwargs = {\"id2label\": id2label, \"label2id\": label2id} if id2label and label2id else {}\n",
    "    hf_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        checkpoint, num_labels=n_labels, compile=False, **model_additional_kwargs\n",
    "    )\n",
    "\n",
    "    hf_data_collator = DataCollatorWithPadding(tokenizer=hf_tokenizer)\n",
    "\n",
    "    # 6. Define the training arguments and trainer\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"aai_ModernBERT_{task}_ft\",\n",
    "        learning_rate=lr,\n",
    "        per_device_train_batch_size=train_bsz,\n",
    "        per_device_eval_batch_size=val_bsz,\n",
    "        num_train_epochs=n_epochs,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        optim=\"adamw_torch\",\n",
    "        adam_beta1=betas[0],\n",
    "        adam_beta2=betas[1],\n",
    "        adam_epsilon=eps,\n",
    "        logging_strategy=\"epoch\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        bf16=True,\n",
    "        bf16_full_eval=True,\n",
    "        push_to_hub=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=hf_model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[train_ds_name],\n",
    "        eval_dataset=tokenized_datasets[valid_ds_name],\n",
    "        processing_class=hf_tokenizer,\n",
    "        data_collator=hf_data_collator,\n",
    "        compute_metrics=task_compute_metrics,\n",
    "    )\n",
    "\n",
    "    # Add callback to trainer\n",
    "    metrics_callback = MetricsCallback()\n",
    "    trainer.add_callback(metrics_callback)\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # 7. Get the training results and hyperparameters\n",
    "    train_history_df = pd.DataFrame(metrics_callback.training_history[\"train\"])\n",
    "    train_history_df = train_history_df.add_prefix(\"train_\")\n",
    "    eval_history_df = pd.DataFrame(metrics_callback.training_history[\"eval\"])\n",
    "    train_res_df = pd.concat([train_history_df, eval_history_df], axis=1)\n",
    "\n",
    "    args_df = pd.DataFrame([training_args.to_dict()])\n",
    "\n",
    "    # 8. Cleanup (optional)\n",
    "    if do_cleanup:\n",
    "        cleanup(things_to_delete=[trainer, hf_model, hf_tokenizer, tokenized_datasets, raw_datasets])\n",
    "\n",
    "    return train_res_df, args_df, hf_model, hf_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helpful function encapsulates all the steps we've been through above and allows us to easily run a fine-tune on a single task. In addition to the HuggingFace objects, it returns the training results, training hyperparameters (all potentially helpful for performing sweeps and or documenting your results).\n",
    "\n",
    "Let's give it a go on both MRPC and CoLA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [230/230 00:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.563700</td>\n",
       "      <td>0.414041</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.872305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.326700</td>\n",
       "      <td>0.371047</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.881295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "      <th>eval_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5637</td>\n",
       "      <td>3.246023</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.414041</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.872305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3267</td>\n",
       "      <td>5.002162</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.371047</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.881295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.5637         3.246023              0.00004          1.0   0.414041   \n",
       "1      0.3267         5.002162              0.00000          2.0   0.371047   \n",
       "\n",
       "   eval_accuracy_score  eval_f1_score  \n",
       "0             0.811275       0.872305  \n",
       "1             0.838235       0.881295  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_mrpc_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_mrpc_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_res_df, args_df, hf_model, hf_tokenizer = finetune_glue_task(\n",
    "    \"mrpc\", checkpoint=\"answerdotai/ModernBERT-base\", do_cleanup=True\n",
    ")\n",
    "\n",
    "display(train_res_df)\n",
    "display(args_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='536' max='536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [536/536 01:14, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Corrcoef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.615100</td>\n",
       "      <td>0.525902</td>\n",
       "      <td>0.323947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.406600</td>\n",
       "      <td>0.441870</td>\n",
       "      <td>0.492141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_matthews_corrcoef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6151</td>\n",
       "      <td>8.100638</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.525902</td>\n",
       "      <td>0.323947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4066</td>\n",
       "      <td>11.885351</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.441870</td>\n",
       "      <td>0.492141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.6151         8.100638              0.00004          1.0   0.525902   \n",
       "1      0.4066        11.885351              0.00000          2.0   0.441870   \n",
       "\n",
       "   eval_matthews_corrcoef  \n",
       "0                0.323947  \n",
       "1                0.492141  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_cola_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_cola_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_res_df, args_df, hf_model, hf_tokenizer = finetune_glue_task(\n",
    "    \"cola\", checkpoint=\"answerdotai/ModernBERT-base\", do_cleanup=True\n",
    ")\n",
    "\n",
    "display(train_res_df)\n",
    "display(args_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Send it!**\n",
    "\n",
    "Grab yourself a good cup of coffee, take your pups out for a walk, or whatever as your GPU purrs along while finetuning all things GLUE!\n",
    "\n",
    "Note the `train_subset` parameter which allows us to train on a subset of the dataset. This is helpful for quickly testing the model on a small dataset to make sure all the bits work as expected.  Feel free to set it to `None` for a full send!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning cola -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Corrcoef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.607800</td>\n",
       "      <td>0.604273</td>\n",
       "      <td>0.043760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.595953</td>\n",
       "      <td>0.228080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_matthews_corrcoef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6078</td>\n",
       "      <td>40.798195</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.604273</td>\n",
       "      <td>0.04376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4050</td>\n",
       "      <td>12.892710</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.595953</td>\n",
       "      <td>0.22808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.6078        40.798195              0.00004          1.0   0.604273   \n",
       "1      0.4050        12.892710              0.00000          2.0   0.595953   \n",
       "\n",
       "   eval_matthews_corrcoef  \n",
       "0                 0.04376  \n",
       "1                 0.22808  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_cola_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_cola_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning sst2 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:27, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.569200</td>\n",
       "      <td>0.393088</td>\n",
       "      <td>0.834862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.313808</td>\n",
       "      <td>0.870413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5692</td>\n",
       "      <td>13.669675</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.393088</td>\n",
       "      <td>0.834862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2314</td>\n",
       "      <td>5.367749</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.313808</td>\n",
       "      <td>0.870413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.5692        13.669675              0.00004          1.0   0.393088   \n",
       "1      0.2314         5.367749              0.00000          2.0   0.313808   \n",
       "\n",
       "   eval_accuracy_score  \n",
       "0             0.834862  \n",
       "1             0.870413  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_sst2_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_sst2_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning mrpc -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:28, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.637600</td>\n",
       "      <td>0.508369</td>\n",
       "      <td>0.752451</td>\n",
       "      <td>0.831386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.427900</td>\n",
       "      <td>0.446494</td>\n",
       "      <td>0.786765</td>\n",
       "      <td>0.851789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "      <th>eval_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6376</td>\n",
       "      <td>13.762523</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.508369</td>\n",
       "      <td>0.752451</td>\n",
       "      <td>0.831386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4279</td>\n",
       "      <td>10.919047</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.446494</td>\n",
       "      <td>0.786765</td>\n",
       "      <td>0.851789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.6376        13.762523              0.00004          1.0   0.508369   \n",
       "1      0.4279        10.919047              0.00000          2.0   0.446494   \n",
       "\n",
       "   eval_accuracy_score  eval_f1_score  \n",
       "0             0.752451       0.831386  \n",
       "1             0.786765       0.851789  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_mrpc_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_mrpc_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning stsb -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearsonr</th>\n",
       "      <th>Spearmanr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.441400</td>\n",
       "      <td>1.323127</td>\n",
       "      <td>0.735928</td>\n",
       "      <td>0.744267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.743600</td>\n",
       "      <td>0.831915</td>\n",
       "      <td>0.802678</td>\n",
       "      <td>0.804716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_pearsonr</th>\n",
       "      <th>eval_spearmanr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4414</td>\n",
       "      <td>43.095963</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.323127</td>\n",
       "      <td>0.735928</td>\n",
       "      <td>0.744267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7436</td>\n",
       "      <td>22.308477</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.831915</td>\n",
       "      <td>0.802678</td>\n",
       "      <td>0.804716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      2.4414        43.095963              0.00004          1.0   1.323127   \n",
       "1      0.7436        22.308477              0.00000          2.0   0.831915   \n",
       "\n",
       "   eval_pearsonr  eval_spearmanr  \n",
       "0       0.735928        0.744267  \n",
       "1       0.802678        0.804716  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_stsb_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_stsb_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning qqp -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/390965 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|██████████| 390965/390965 [00:33<00:00, 11761.24 examples/s]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 01:27, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.607400</td>\n",
       "      <td>0.499629</td>\n",
       "      <td>0.621215</td>\n",
       "      <td>0.728321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.524866</td>\n",
       "      <td>0.615188</td>\n",
       "      <td>0.732278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_f1_score</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6074</td>\n",
       "      <td>8.23535</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499629</td>\n",
       "      <td>0.621215</td>\n",
       "      <td>0.728321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4850</td>\n",
       "      <td>36.08305</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.524866</td>\n",
       "      <td>0.615188</td>\n",
       "      <td>0.732278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.6074          8.23535              0.00004          1.0   0.499629   \n",
       "1      0.4850         36.08305              0.00000          2.0   0.524866   \n",
       "\n",
       "   eval_f1_score  eval_accuracy_score  \n",
       "0       0.621215             0.728321  \n",
       "1       0.615188             0.732278  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_qqp_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              output_dir  overwrite_output_dir  do_train  do_eval  do_predict  \\\n",
       "0  aai_modernbert_qqp_ft                 False     False     True       False   \n",
       "\n",
       "  eval_strategy  prediction_loss_only  per_device_train_batch_size  \\\n",
       "0         epoch                 False                           32   \n",
       "\n",
       "   per_device_eval_batch_size per_gpu_train_batch_size  ... split_batches  \\\n",
       "0                          32                     None  ...          None   \n",
       "\n",
       "   include_tokens_per_second include_num_input_tokens_seen  \\\n",
       "0                      False                         False   \n",
       "\n",
       "   neftune_noise_alpha optim_target_modules  batch_eval_metrics  \\\n",
       "0                 None                 None               False   \n",
       "\n",
       "   eval_on_start  use_liger_kernel  eval_use_gather_object  \\\n",
       "0          False             False                   False   \n",
       "\n",
       "   average_tokens_across_devices  \n",
       "0                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning mnli-matched -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/9847 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|██████████| 9847/9847 [00:01<00:00, 9226.73 examples/s]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:46, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.147100</td>\n",
       "      <td>1.068802</td>\n",
       "      <td>0.406215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.935800</td>\n",
       "      <td>1.027365</td>\n",
       "      <td>0.471014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1471</td>\n",
       "      <td>7.386725</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.068802</td>\n",
       "      <td>0.406215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9358</td>\n",
       "      <td>13.833081</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.027365</td>\n",
       "      <td>0.471014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      1.1471         7.386725              0.00004          1.0   1.068802   \n",
       "1      0.9358        13.833081              0.00000          2.0   1.027365   \n",
       "\n",
       "   eval_accuracy_score  \n",
       "0             0.406215  \n",
       "1             0.471014  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_mnli-matched_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_mnli-matched_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning mnli-mismatched -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:46, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.147100</td>\n",
       "      <td>1.055565</td>\n",
       "      <td>0.423922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.935500</td>\n",
       "      <td>1.011183</td>\n",
       "      <td>0.494304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1471</td>\n",
       "      <td>7.386725</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.055565</td>\n",
       "      <td>0.423922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9355</td>\n",
       "      <td>12.523493</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.011183</td>\n",
       "      <td>0.494304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      1.1471         7.386725              0.00004          1.0   1.055565   \n",
       "1      0.9355        12.523493              0.00000          2.0   1.011183   \n",
       "\n",
       "   eval_accuracy_score  \n",
       "0             0.423922  \n",
       "1             0.494304  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_mnli-mismatched_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_mnli-mismatched_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning qnli -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/5463 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|██████████| 5463/5463 [00:00<00:00, 7358.18 examples/s]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:39, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.695700</td>\n",
       "      <td>0.526290</td>\n",
       "      <td>0.742998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.417700</td>\n",
       "      <td>0.603152</td>\n",
       "      <td>0.731832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6957</td>\n",
       "      <td>69.748146</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.526290</td>\n",
       "      <td>0.742998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4177</td>\n",
       "      <td>16.136906</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.603152</td>\n",
       "      <td>0.731832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.6957        69.748146              0.00004          1.0   0.526290   \n",
       "1      0.4177        16.136906              0.00000          2.0   0.603152   \n",
       "\n",
       "   eval_accuracy_score  \n",
       "0             0.742998  \n",
       "1             0.731832  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_qnli_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_qnli_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning rte -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|██████████| 3000/3000 [00:00<00:00, 5602.09 examples/s]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:32, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.755100</td>\n",
       "      <td>0.707934</td>\n",
       "      <td>0.509025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.655600</td>\n",
       "      <td>0.690976</td>\n",
       "      <td>0.498195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7551</td>\n",
       "      <td>5.044735</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707934</td>\n",
       "      <td>0.509025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6556</td>\n",
       "      <td>6.338690</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.690976</td>\n",
       "      <td>0.498195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.7551         5.044735              0.00004          1.0   0.707934   \n",
       "1      0.6556         6.338690              0.00000          2.0   0.690976   \n",
       "\n",
       "   eval_accuracy_score  \n",
       "0             0.509025  \n",
       "1             0.498195  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_rte_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              output_dir  overwrite_output_dir  do_train  do_eval  do_predict  \\\n",
       "0  aai_modernbert_rte_ft                 False     False     True       False   \n",
       "\n",
       "  eval_strategy  prediction_loss_only  per_device_train_batch_size  \\\n",
       "0         epoch                 False                           32   \n",
       "\n",
       "   per_device_eval_batch_size per_gpu_train_batch_size  ... split_batches  \\\n",
       "0                          32                     None  ...          None   \n",
       "\n",
       "   include_tokens_per_second include_num_input_tokens_seen  \\\n",
       "0                      False                         False   \n",
       "\n",
       "   neftune_noise_alpha optim_target_modules  batch_eval_metrics  \\\n",
       "0                 None                 None               False   \n",
       "\n",
       "   eval_on_start  use_liger_kernel  eval_use_gather_object  \\\n",
       "0          False             False                   False   \n",
       "\n",
       "   average_tokens_across_devices  \n",
       "0                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning wnli -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/146 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|██████████| 146/146 [00:00<00:00, 5646.34 examples/s]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:25, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.789800</td>\n",
       "      <td>0.709700</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.718300</td>\n",
       "      <td>0.691901</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7898</td>\n",
       "      <td>6.372931</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.709700</td>\n",
       "      <td>0.56338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7183</td>\n",
       "      <td>3.087399</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.691901</td>\n",
       "      <td>0.56338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.7898         6.372931              0.00004          1.0   0.709700   \n",
       "1      0.7183         3.087399              0.00000          2.0   0.691901   \n",
       "\n",
       "   eval_accuracy_score  \n",
       "0              0.56338  \n",
       "1              0.56338  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_wnli_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_wnli_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for task in glue_tasks.keys():\n",
    "    print(f\"----- Finetuning {task} -----\")\n",
    "    train_res_df, args_df, hf_model, hf_tokenizer = finetune_glue_task(\n",
    "        task, checkpoint=\"answerdotai/ModernBERT-base\", train_subset=1_000, do_cleanup=True\n",
    "    )\n",
    "\n",
    "    print(\":: Results ::\")\n",
    "    display(train_res_df)\n",
    "    display(args_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "With ModernBERT encoders are back baby!  We've seen that ModernBERT-base can compete with the best of them on GLUE tasks and with a little more tuning, we'll see that ModernBERT-large can do even better.  I'm excited to see what the community will do with this model and I'm looking forward to seeing what you all build with it! We'll be exploring more of the capabilities of ModernBERT in future tutorials.\n",
    "\n",
    "Until next time, happy coding!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert24-h200",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
